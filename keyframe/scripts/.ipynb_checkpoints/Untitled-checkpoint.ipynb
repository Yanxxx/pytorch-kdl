{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "773118f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import dataset\n",
    "from attention import Attention2D\n",
    "import utils as utils\n",
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from os import mkdir, getcwd\n",
    "from os.path import join, dirname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98b5cb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rot, t = utils.camTrans()\n",
    "model = Attention2D() #.to(device)\n",
    "model_path = '../checkpoints/spatial-softmax/20210715-175329/checkpoint-2000.pth'\n",
    "md = torch.load(model_path)\n",
    "ts = md['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf6a96fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(md['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d62f467e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def euler2rotm(theta):\n",
    "    R_x = np.array([[1,         0,                  0                   ],\n",
    "                    [0,         math.cos(theta[0]), -math.sin(theta[0]) ],\n",
    "                    [0,         math.sin(theta[0]), math.cos(theta[0])  ]\n",
    "                    ])\n",
    "    R_y = np.array([[math.cos(theta[1]),    0,      math.sin(theta[1])  ],\n",
    "                    [0,                     1,      0                   ],\n",
    "                    [-math.sin(theta[1]),   0,      math.cos(theta[1])  ]\n",
    "                    ])         \n",
    "    R_z = np.array([[math.cos(theta[2]),    -math.sin(theta[2]),    0],\n",
    "                    [math.sin(theta[2]),    math.cos(theta[2]),     0],\n",
    "                    [0,                     0,                      1]\n",
    "                    ])            \n",
    "    R = np.dot(R_z, np.dot( R_y, R_x ))\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4b56613e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.85617374 -0.27798709  0.43553381]\n",
      " [ 0.31443745  0.94919877 -0.01227939]\n",
      " [-0.40999464  0.14746143  0.90008862]] [[450   0 320]\n",
      " [  0 450 240]\n",
      " [  0   0   1]]\n"
     ]
    }
   ],
   "source": [
    "R = euler2rotm(np.random.rand(3))\n",
    "camera_intrinsic=np.array([[450, 0 , 320], [0, 450, 240], [0, 0, 1]])\n",
    "ifx = 32/45\n",
    "ify = 24/45\n",
    "pos_x, pos_y = np.meshgrid(\n",
    "        np.linspace(-1., 1., 240),\n",
    "        np.linspace(-1., 1., 320)\n",
    "        )\n",
    "pos_x *= ifx\n",
    "pos_y *= ify\n",
    "print(R, camera_intrinsic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8bc4455c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Conv2d(3, 3, 1)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        return self.l1(data)\n",
    "    \n",
    "class BackProjectionNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Conv2d(2,2,1)\n",
    "        pos_x, pos_y = np.meshgrid(\n",
    "                np.linspace(-1., 1., self.height),\n",
    "                np.linspace(-1., 1., self.width)\n",
    "                )\n",
    "        pos_x = torch.Tensor(pos_x).float()\n",
    "        pos_y = torch.Tensor(pos_y).float()\n",
    "        self.register_buffer('pos_x', pos_x)\n",
    "        self.register_buffer('pos_y', pos_y)\n",
    "        self.xy = torch.cat((pos_x[None,:], pos_y[None, :]), 0)\n",
    "        self.ones = torch.ones(height, width)\n",
    "        self.l1 = nn.Conv2d(2, 2, 1)\n",
    "        self.l2 = nn.Conv2d(3, 3, 1)\n",
    "    def forward(self, data):\n",
    "        return self.l1(data)\n",
    "\n",
    "class CoordinateTransformer(nn.Module):\n",
    "    \n",
    "    def __init__(self, height, width):\n",
    "#         super(CoordinateTransformer).__init__()\n",
    "        super().__init__()\n",
    "        \n",
    "        pos_x, pos_y = np.meshgrid(\n",
    "                np.linspace(-1., 1., height),\n",
    "                np.linspace(-1., 1., width)\n",
    "                )\n",
    "        pos_x = torch.Tensor(pos_x).float()\n",
    "        pos_y = torch.Tensor(pos_y).float()\n",
    "#         self.register_buffer('pos_x', pos_x)\n",
    "#         self.register_buffer('pos_y', pos_y)\n",
    "        self.xy = torch.cat((pos_x[None,:], pos_y[None, :]), 0)\n",
    "        self.ones = torch.ones(height, width)\n",
    "        self.l1 = nn.Conv2d(2, 2, 1)\n",
    "        self.l2 = nn.Conv2d(3, 3, 1)\n",
    "        \n",
    "    def forward(self, depth):\n",
    "        output = self.l1(self.xy)\n",
    "        output = torch.cat((output, self.ones[None, :]), 0)\n",
    "        output = output * depth\n",
    "        output = self.l2(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "124dab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_len = 2000000\n",
    "# def dataset(data_len):\n",
    "#     data = torch.rand((data_len,3,1,1))\n",
    "#     Rot = torch.Tensor(R)\n",
    "#     reshape_data = torch.transpose(torch.squeeze(data), 1, 0)\n",
    "# #     print(reshape_data.shape)\n",
    "#     output = torch.matmul(Rot, reshape_data)\n",
    "#     output = torch.transpose(output, 1, 0).reshape((data_len,3,1,1))\n",
    "#     return data, output\n",
    "# #     print(output.shape)\n",
    "\n",
    "class dataset:\n",
    "    def __init__(self, height=240,width=320):\n",
    "        self.R = np.eye(3)\n",
    "#         camera_intrinsic=np.array([[450, 0 , 320], [0, 450, 240], [0, 0, 1]])\n",
    "        ifx = 32/45\n",
    "        ify = 24/45\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        pos_x, pos_y = np.meshgrid(\n",
    "                np.linspace(-1., 1., height),\n",
    "                np.linspace(-1., 1., width)\n",
    "                )\n",
    "        pos_x = torch.Tensor(pos_x).float()\n",
    "        pos_y = torch.Tensor(pos_y).float()\n",
    "        pos_x *= ifx\n",
    "        pos_y *= ify\n",
    "        ones = torch.ones(width, height)\n",
    "        \n",
    "        print(pos_x.shape, pos_y.shape, ones.shape)\n",
    "        \n",
    "        self.base = torch.cat((pos_x[None,:], pos_y[None,:], ones[None, :]), 0)\n",
    "        \n",
    "        self.base.reshape(1, 3, height, width)\n",
    "\n",
    "        \n",
    "    def RandomRot(self):\n",
    "        self.R = self.euler2rotm(np.random.rand(3))\n",
    "        \n",
    "    def euler2rotm(self,theta):\n",
    "        R_x = np.array([[1,         0,                  0                   ],\n",
    "                        [0,         math.cos(theta[0]), -math.sin(theta[0]) ],\n",
    "                        [0,         math.sin(theta[0]), math.cos(theta[0])  ]\n",
    "                        ])\n",
    "        R_y = np.array([[math.cos(theta[1]),    0,      math.sin(theta[1])  ],\n",
    "                        [0,                     1,      0                   ],\n",
    "                        [-math.sin(theta[1]),   0,      math.cos(theta[1])  ]\n",
    "                        ])         \n",
    "        R_z = np.array([[math.cos(theta[2]),    -math.sin(theta[2]),    0],\n",
    "                        [math.sin(theta[2]),    math.cos(theta[2]),     0],\n",
    "                        [0,                     0,                      1]\n",
    "                        ])            \n",
    "        R = np.dot(R_z, np.dot( R_y, R_x ))\n",
    "        return R\n",
    "    \n",
    "    def get(self, length):\n",
    "        depth = torch.randn(length, 1, self.height, self.width)\n",
    "        pc = self.base * depth\n",
    "        pc = torch.matmul(self.R, pc)\n",
    "        return depth, pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d9ea1d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([320, 240]) torch.Size([320, 240]) torch.Size([240, 320])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 0. Got 320 and 240 in dimension 1 (The offending index is 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-ff2ba6d7de0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultiStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmilestones\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m60000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m80000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomRot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-65-e6d00c6e77a8>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, height, width)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mones\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mones\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 0. Got 320 and 240 in dimension 1 (The offending index is 2)"
     ]
    }
   ],
   "source": [
    "model = CoordinateTransformer(240,320)\n",
    "\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate,momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[20000,30000,60000,80000], gamma=0.1)\n",
    "\n",
    "data = dataset()\n",
    "data.RandomRot()\n",
    "\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "for i in range(500):\n",
    "    x, y_pred = data(5000)\n",
    "    y = model(x)\n",
    "    loss = loss_fn(y, y_pred)\n",
    "#     print(i, loss.item())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    x_val, y_val = data(5000)\n",
    "    y_h = model(x_val)\n",
    "    loss_val = loss_fn(y_h, y_val)\n",
    "    print(i, 'train: ', loss.item(), ', val: ', loss_val.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d5ae6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c9e4e60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 31)\n"
     ]
    }
   ],
   "source": [
    "pos_x, pos_y = np.meshgrid(\n",
    "                np.linspace(-1., 1., 31),\n",
    "                np.linspace(-1., 1., 21)\n",
    "                )\n",
    "print(pos_x.shape)\n",
    "pos_x = torch.Tensor(pos_x).float()\n",
    "pos_y = torch.Tensor(pos_y).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c3b76f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 21, 31])\n"
     ]
    }
   ],
   "source": [
    "tx = torch.cat((pos_x[None,:], pos_y[None, :]), 0)\n",
    "ones = torch.ones(21, 31)\n",
    "output = torch.cat((tx, ones[None,:]), 0)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f8e39dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 21, 31])\n"
     ]
    }
   ],
   "source": [
    "z = torch.rand(1, 21, 31)\n",
    "pc = output * z\n",
    "print(pc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5cf459af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]]]) tensor([[[5., 5., 5., 5.],\n",
      "         [5., 5., 5., 5.],\n",
      "         [5., 5., 5., 5.]]])\n",
      "tensor([[[5., 5., 5., 5.],\n",
      "         [5., 5., 5., 5.],\n",
      "         [5., 5., 5., 5.]],\n",
      "\n",
      "        [[5., 5., 5., 5.],\n",
      "         [5., 5., 5., 5.],\n",
      "         [5., 5., 5., 5.]],\n",
      "\n",
      "        [[5., 5., 5., 5.],\n",
      "         [5., 5., 5., 5.],\n",
      "         [5., 5., 5., 5.]]])\n"
     ]
    }
   ],
   "source": [
    "txy = torch.ones((3,3,4))\n",
    "tz = torch.ones((1,3,4)) * 5\n",
    "print(txy, tz)\n",
    "print(txy * tz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2ec33dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 3, 4]) tensor([[[[2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2.]],\n",
      "\n",
      "         [[2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2.]],\n",
      "\n",
      "         [[2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2.]]],\n",
      "\n",
      "\n",
      "        [[[2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2.]],\n",
      "\n",
      "         [[2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2.]],\n",
      "\n",
      "         [[2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2.]]]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(2,1,3,4)\n",
    "b = torch.ones(1,3,3,4) * 2\n",
    "c = a * b\n",
    "print(c.shape,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da4b3b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
